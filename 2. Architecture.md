# Архитектура Kafka: как работает и из чего состоит
![image](https://user-images.githubusercontent.com/98359811/232869903-612ce826-71b3-4739-b1ed-e420a10747ba.png)

## Topic 

1. Это основная абстракция Apache Kafka.
2.Это большая труба для передачи сообщений. Иначе, topic – поток сообщений.
3. Внутри Kafka данные хранятся в виде topics. Каждый topic идентифицируется своим именем.
4. Можно создавать сколько угодно topics.
5. Данные в topics по умолчанию удаляются через 1 неделю, но это значение можно настраивать.
6. Producer записывают свои данные в topic, а consumer читает данные из этого topic.
7. Данные в topics по умолчанию удаляются через 1 неделю, но это значение можно настраивать.
8. Producer записывают свои данные в topic, а consumer читает данные из этого topic.

## Partition 

1. Topics делятся на настраиваемое количество частей, которые называются partitions.
2. Partition разделяет topic по нескольким серверам (брокерам), снижая нагрузку на каждый отдельный сервер.

## Offset

1. Каждое сообщение в partition получает номер, или offset, чтобы определить положение в partition.
2. Offset, порядковый номер сообщения в partition.
3. По умолчанию offset начинается с 0 для каждого partition и увеличивается на 1 каждый раз при получении нового сообщения.

![image](https://user-images.githubusercontent.com/98359811/232870277-170996c0-3ce6-4779-9b46-cd72c4e7d616.png)

## Broker

1. Кластер Kafka состоит из одного или нескольких серверов, известных как brokers.
2. В кластер Kafka также входит кластер Zookeeper,
который хранит метаданные.
3. Уникальный ID используется для идентификации broker в кластере Kafka.
![image](https://user-images.githubusercontent.com/98359811/232870364-c9cdab95-8144-4728-bb36-9313eb27d656.png)

4. В Kafka broker работает как контейнер, который может содержать несколько partitions разных топиков.
![image](https://user-images.githubusercontent.com/98359811/232870435-ac149a44-3bc5-45d0-ba13-3c6e6ef83e99.png)

5. Подключение к любому из Kafka brokers в кластере подразумевает подключение ко всему кластеру.

## Replica

1. Replicas похожи на резервную копию partition в Kafka. Каждый partition дублируется для увеличения надежности хранения данных.
2. В одном partition есть несколько разных replicas и какая-то из них главная – Leader для partition.
3. Leader replica взаимодействует с consumers и producers. Остальные replicas синхронизируются с leader replica.
4. Если broker, на котором находится leader replica, перестает работать, среди копий выбирается новый leader.

![image](https://user-images.githubusercontent.com/98359811/232870534-779f82b5-1493-4d4e-a7ed-d0e48a8666e2.png)

## Producer 

1. Пишет сообщения в один или несколько topics.
2. Producers автоматически знают, какие данные должны быть записаны в какой partition и какой broker.
    - У Kafka умный клиент.
    - Пользователю не требуется указывать broker и partition.
    - В случае сбоя broker, producer автоматически восстанавливается.
3. Нагрузка балансируется по разным brokers и partitions.

![image](https://user-images.githubusercontent.com/98359811/232871058-5f115ce5-75b5-41dd-be31-a02923226938.png)

## Consumer and Consumer group

1. Consumers читают сообщения из topics, на которые они подписаны.
2. В случае сбоя broker consumers знают, как восстановиться.
3. Знают из какого broker (leader replica) читать сообщения. (Умный Kafka Client.) 
4. Сообщения из одного partition читаются строго в порядке добавления, FIFO.
5. Данные из разных partition могут перемешиваться любым способом.

![image](https://user-images.githubusercontent.com/98359811/232871408-67162341-62e1-4939-93dc-4262f3bdc23c.png)

6. Consumer group объединяет несколько consumers, таким образом, что каждый consumer читает часть сообщений определенного topic.
 Consumer group используется для масштабирования чтения сообщений.
 
 ![image](https://user-images.githubusercontent.com/98359811/232871600-7ad56b71-4701-408d-987d-f8898280b3ae.png)

## ZooKeeper

1. Подкластер, хранящий метаданные о них и о topics.
2. Содержит актуальный список всех brokers, topics, partitions...
3. С версии Kafka 2.8.0 его функции выполняет Qourum Controller.

## Инструменты, расширяющие возможности Kafka

1. Kafka Streams - Клиентская библиотека для обработки и анализа потоков данных в real-time с помощью Kafka.
2. Kafka Connect - Фреймворк, обеспечивающий передачу данных между Kafka и другими системами или хранилищами данных.
3. Kafka Schema Registry - Служба, которая управляет схемами данных, хранящихся в Kafka, обеспечивая совместимость и согласованность в различных приложениях и системах.
4. Библиотеки, плагины и интеграции, разработанные коммьюнити
